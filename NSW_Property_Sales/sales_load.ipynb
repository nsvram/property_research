{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data location\n",
    "#### https://valuation.property.nsw.gov.au/embed/propertySalesInformation\n",
    "#### http://www.valuergeneral.nsw.gov.au/__psi/weekly/20181001.zip \n",
    "#### http://www.valuergeneral.nsw.gov.au/__psi/yearly/2017.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata\n",
    "http://www.valuergeneral.nsw.gov.au/__data/assets/pdf_file/0015/216402/Current_Property_Sales_Data_File_Format_2001_to_Current.pdf\n",
    "http://www.valuergeneral.nsw.gov.au/__data/assets/pdf_file/0016/216403/Property_Sales_Data_File_-_Data_Elements_V3.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import collections\n",
    "import requests\n",
    "import os\n",
    "import requests\n",
    "import io\n",
    "import zipfile\n",
    "import datetime\n",
    "import time \n",
    "import glob\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weekly load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sales_data(file_path, folder_level=-2):\n",
    "    dat_files = [f for f in glob.glob(\"{0}*.DAT\".format(file_path))]\n",
    "    foldername = (file_path.split(\"/\")[folder_level])\n",
    "    print(\"Loading sales data for the date - \" + foldername)\n",
    "    try:\n",
    "        os.remove(\"../data/sales/A_str/{0}.csv\".format(foldername))\n",
    "        os.remove(\"../data/sales/B_str/{0}.csv\".format(foldername))\n",
    "        os.remove(\"../data/sales/C_str/{0}.csv\".format(foldername))\n",
    "        os.remove(\"../data/sales/D_str/{0}.csv\".format(foldername))\n",
    "        os.remove(\"../data/sales/Z_str/{0}.csv\".format(foldername))\n",
    "    except OSError:\n",
    "        pass\n",
    "    for i in dat_files:\n",
    "        A_str = \"\"\n",
    "        B_str = \"\"\n",
    "        C_str = \"\"\n",
    "        D_str = \"\"\n",
    "        Z_str = \"\"\n",
    "        with open(i) as f:\n",
    "            lis=[line.split() for line in f]\n",
    "            for i in lis:\n",
    "                if (\"\".join(i)).split(\";\")[0] == 'A':\n",
    "                    A_str =  A_str + \";\".join((\"\".join(i)).split(\";\")) + \"\\n\"\n",
    "                if (\"\".join(i)).split(\";\")[0] == 'B':\n",
    "                    B_str = B_str + \";\".join((\"\".join(i)).split(\";\")) + \"\\n\"\n",
    "                if (\"\".join(i)).split(\";\")[0] == 'C':\n",
    "                    C_str = C_str + \";\".join((\"\".join(i)).split(\";\")) + \"\\n\"\n",
    "                if (\"\".join(i)).split(\";\")[0] == 'D':\n",
    "                    D_str = D_str + \";\".join((\"\".join(i)).split(\";\")) + \"\\n\"\n",
    "                if (\"\".join(i)).split(\";\")[0] == 'Z':\n",
    "                    Z_str = Z_str + \";\".join((\"\".join(i)).split(\";\")) + \"\\n\"\n",
    "        with open(\"../data/sales/A_str/{0}.csv\".format(foldername), \"a\") as a_myfile:\n",
    "            a_myfile.write(A_str)\n",
    "        with open(\"../data/sales/B_str/{0}.csv\".format(foldername), \"a\") as b_myfile:\n",
    "            b_myfile.write(B_str)\n",
    "        with open(\"../data/sales/C_str/{0}.csv\".format(foldername), \"a\") as c_myfile:\n",
    "            c_myfile.write(C_str)\n",
    "        with open(\"../data/sales/D_str/{0}.csv\".format(foldername), \"a\") as d_myfile:\n",
    "            d_myfile.write(D_str)\n",
    "        with open(\"../data/sales/Z_str/{0}.csv\".format(foldername), \"a\") as z_myfile:\n",
    "            z_myfile.write(Z_str)\n",
    "\n",
    "def download_extract_zip(url):\n",
    "    response = requests.get(url)\n",
    "    if (response.status_code==200):\n",
    "        with zipfile.ZipFile(io.BytesIO(response.content)) as thezip:\n",
    "            path2download = \"../data/temp/{0}/\".format((url.split(\"/\")[-1]).replace(\".zip\",\"\"))\n",
    "            thezip.extractall(path2download)\n",
    "            print(\"Files are downloaded successfully in {0} !!!\".format(path2download))\n",
    "            load_sales_data(path2download)\n",
    "            #return path2download\n",
    "    else:\n",
    "        print(\"No data found\")\n",
    "#download_extract_zip(url)                \n",
    "\n",
    "\n",
    "\n",
    "def property_price_sq_meter(row):\n",
    "    if row['Area_Type'] == 'M':\n",
    "        return  row['Purchase_Price'] / row['Area']\n",
    "    if row['Area_Type'] =='H':\n",
    "        return  row['Purchase_Price'] / (row['Area'] * 10000)\n",
    "\n",
    "\n",
    "    \n",
    "def sale_datamart(year):    \n",
    "    col_header =['Record_Type',\n",
    "    'District_Code',\n",
    "    'Property_Id',\n",
    "    'Sale_Counter',\n",
    "    'Download_Date_Time',\n",
    "    'Property_Name',\n",
    "    'Property_Unit_Number',\n",
    "    'Property_House_Number',\n",
    "    'Property_Street_Name',\n",
    "    'Property_Locality',\n",
    "    'Property_Post_Code',\n",
    "    'Area',\n",
    "    'Area_Type',\n",
    "    'Contract_Date',\n",
    "    'Settlement_Date',\n",
    "    'Purchase_Price',\n",
    "    'Zoning',\n",
    "    'Nature_of_Property',\n",
    "    'Primary_Purpose',\n",
    "    'Strata_Lot_Number',\n",
    "    'Component_code',\n",
    "    'Sale_Code',\n",
    "    'Percentage_Interest_of_Sale',\n",
    "    'Dealing_Number',\n",
    "    'Empty']\n",
    "    \n",
    "    print(\"Loading datamart .. \"  + '../data/sales/B_str/{0}.csv'.format(year))\n",
    "    lst_pds = [pd.read_csv(f, \n",
    "                           sep=';', \n",
    "                           error_bad_lines=False, \n",
    "                           quoting=csv.QUOTE_NONE, \n",
    "                           header=None ,  \n",
    "                           encoding='utf-8',\n",
    "                           index_col=None\n",
    "                          ) for f in glob.glob('../data/sales/B_str/{0}.csv'.format(year))]\n",
    "    \n",
    "    df_sale = pd.concat(lst_pds)\n",
    "    df_sale.columns = col_header\n",
    "    # Add Downloaded_Date from \n",
    "    df_sale['Download_Date'] = pd.to_datetime(df_sale['Download_Date_Time'].str[:8]) \n",
    "    \n",
    "    #Deduplicate \n",
    "    df_sale_dedup = df_sale.drop_duplicates(subset=[i for i in df_sale.columns if i != 'Download_Date'], keep=False)\n",
    "    df_sale_dedup['Property_Price_Sq_Meter'] = df_sale_dedup.apply(property_price_sq_meter, axis=1)\n",
    "    \n",
    "    # Build Data mart\n",
    "    cols_lst     = ['Download_Date','Property_Locality', \"Property_Post_Code\"]\n",
    "    cols_lst_key = [\"Property_Price_Sq_Meter\", \"Purchase_Price\"]\n",
    "    agg_lst      = ['mean','count', 'min', 'max', 'median','std']\n",
    "    \n",
    "    df_time_ser_price = df_sale_dedup[(df_sale.Nature_of_Property == 'R')]\\\n",
    "                                        [cols_lst + cols_lst_key ]\\\n",
    "                                            .groupby(cols_lst)\\\n",
    "                                            .agg(agg_lst)\n",
    "    \n",
    "    df_time_ser_price =  df_time_ser_price.reset_index()\n",
    "    df_time_ser_price.columns = cols_lst + [grp + '_' + agg for grp in cols_lst_key for agg in agg_lst]\n",
    "    print(len(df_time_ser_price))\n",
    "    # Export to csv file \n",
    "    df_time_ser_price.to_csv('../data/sales/sales_{}_data_mart.csv'.format(year),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.valuergeneral.nsw.gov.au/__psi/weekly/20181010.zip\n",
      "No data found\n",
      "http://www.valuergeneral.nsw.gov.au/__psi/weekly/20181009.zip\n",
      "No data found\n",
      "http://www.valuergeneral.nsw.gov.au/__psi/weekly/20181008.zip\n",
      "Files are downloaded successfully in ../data/temp/20181008/ !!!\n",
      "Loading sales data for the date - 20181008\n",
      "http://www.valuergeneral.nsw.gov.au/__psi/weekly/20181007.zip\n",
      "No data found\n",
      "http://www.valuergeneral.nsw.gov.au/__psi/weekly/20181006.zip\n",
      "No data found\n",
      "http://www.valuergeneral.nsw.gov.au/__psi/weekly/20181005.zip\n",
      "No data found\n",
      "http://www.valuergeneral.nsw.gov.au/__psi/weekly/20181004.zip\n",
      "No data found\n",
      "http://www.valuergeneral.nsw.gov.au/__psi/weekly/20181003.zip\n",
      "No data found\n",
      "http://www.valuergeneral.nsw.gov.au/__psi/weekly/20181002.zip\n",
      "No data found\n",
      "http://www.valuergeneral.nsw.gov.au/__psi/weekly/20181001.zip\n",
      "Files are downloaded successfully in ../data/temp/20181001/ !!!\n",
      "Loading sales data for the date - 20181001\n",
      "9.229669094085693\n"
     ]
    }
   ],
   "source": [
    "# Weekly load \n",
    "days_to_load = 10\n",
    "\n",
    "\n",
    "ts = time.time()\n",
    "for i in range(0, days_to_load):\n",
    "    a = str(datetime.date.today() - datetime.timedelta(i)).replace(\"-\",\"\")\n",
    "    url = 'http://www.valuergeneral.nsw.gov.au/__psi/weekly/{0}.zip'.format(a)\n",
    "    print(url)\n",
    "    download_extract_zip(url)\n",
    "te = time.time()\n",
    "print(te-ts)\n",
    "#185.92472124099731"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datamart .. ../data/sales/B_str/2018*.csv\n",
      "40166\n"
     ]
    }
   ],
   "source": [
    "sale_datamart(\"2018*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### History Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Yearly load - time delta for [2017,2016,2015] = 491.8507146835327\n",
    "#ts = time.time()\n",
    "#\n",
    "#for yr in range(2017,2018):\n",
    "#    url = 'http://www.valuergeneral.nsw.gov.au/__psi/yearly/{0}.zip'.format(yr)\n",
    "#    print(url)\n",
    "#    download_extract_zip(url)\n",
    "#    \n",
    "#    ## Extract weekly zip files \n",
    "#    dat_files = [f for f in glob.glob(\"../data/temp/{0}/*.zip\".format(yr))]\n",
    "#    for file in dat_files:\n",
    "#        with zipfile.ZipFile(file) as thezip:\n",
    "#            thezip.extractall(\"../data/temp/{0}/\".format(yr))\n",
    "#    \n",
    "#    # Load yearly data \n",
    "#    # For 2015 alone - since it follows different folder struture\n",
    "#    if (yr in [2015]):\n",
    "#        load_sales_data(\"../data/temp/{0}/*/\".format(yr),-3)\n",
    "#    if (yr in [2016,2017]):\n",
    "#        load_sales_data(\"../data/temp/{0}/\".format(yr),-2)\n",
    "#    else:\n",
    "#        load_sales_data(\"../data/temp/{0}/{0}/*/\".format(yr),-3)\n",
    "#te = time.time()\n",
    "#print(te-ts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Mart Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013\n",
      "Loading datamart .. ../data/sales/B_str/2013.csv\n",
      "49836\n",
      "2014\n",
      "Loading datamart .. ../data/sales/B_str/2014.csv\n",
      "52925\n",
      "2015\n",
      "Loading datamart .. ../data/sales/B_str/2015.csv\n",
      "40883\n",
      "2016\n",
      "Loading datamart .. ../data/sales/B_str/2016.csv\n",
      "53492\n",
      "2017\n",
      "Loading datamart .. ../data/sales/B_str/2017.csv\n",
      "55046\n"
     ]
    }
   ],
   "source": [
    "## History Load \n",
    "for yr in range(2013,2018):\n",
    "    print(yr)\n",
    "    sale_datamart(yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '../data/temp/*': No such file or directory\n",
      "rm: cannot remove '../data/sales/*/*.csv': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Clean up temp space\n",
    "#! rm -r ../data/temp/*\n",
    "#! rm -r ../data/sales/*/'*.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
